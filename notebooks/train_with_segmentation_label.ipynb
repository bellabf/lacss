{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kks5J-TD8-Bh"
   },
   "source": [
    "# LACSS Supervised Training Demo\n",
    "\n",
    "This notebook shows the general workflow of supervised training an LACSS model from scratch. \n",
    "\n",
    "This data uses a small dataset from the [Cell Image Library](http://www.cellimagelibrary.org/home) collection.\n",
    "\n",
    "We will go through these steps:\n",
    "\n",
    "- Setup the data pipeline\n",
    "- Initialize a model trainer\n",
    "- Perform model training\n",
    "- Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jp1Y6zHl9ddY"
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ivh9LzC89QK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"jax[cuda12]==0.4.28\"\n",
    "!pip install git+https://github.com/jiyuuchc/lacss\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from lacss.utils import show_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr0QliBABDOh"
   },
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rqdox1oOccv4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "!wget -c https://data.mendeley.com/public-files/datasets/894mmsd9nj/files/568e524f-9a95-45a6-9f80-3619969c2a37/file_downloaded -O images.zip\n",
    "\n",
    "import zipfile\n",
    "\n",
    "data_path = Path('image_data')\n",
    "\n",
    "with zipfile.ZipFile('images.zip', \"r\") as f:\n",
    "    f.extractall(data_path)\n",
    "\n",
    "show_images([\n",
    "    imageio.imread(data_path / 'train' / '000_img.png'),\n",
    "    imageio.imread(data_path / 'train'/ '000_masks.png'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3bSK8QDEKlM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from os.path import join\n",
    "\n",
    "import lacss.data\n",
    "\n",
    "def parser(data):\n",
    "    image = data['image']\n",
    "    label = data['label']\n",
    "    locations = data['centroids']\n",
    "\n",
    "    # normalize image\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "\n",
    "    # pad the locations tensor so that all elements of the dataset are of the same shape\n",
    "    n_pad = 512 - len(locations)\n",
    "    locations = tf.pad(locations, [[0, n_pad], [0,0]], constant_values=-1)\n",
    "\n",
    "    return (\n",
    "        dict(\n",
    "            image = image,\n",
    "            gt_locations = locations, \n",
    "        ),  # these are inputs to the model, the dict keys match the model's argnames\n",
    "        dict(\n",
    "            gt_labels = label,\n",
    "        ), # these are extra labels for the training\n",
    "    )\n",
    "\n",
    "imgfiles = [data_path/'train'/f'{k:03d}_img.png' for k in range(89)]\n",
    "maskfiles = [data_path/'train'/f'{k:03d}_masks.png' for k in range(89)]\n",
    "\n",
    "# create a tensowflow dataset from the files on disk\n",
    "ds = (\n",
    "    lacss.data.dataset_from_img_mask_pairs(imgfiles, maskfiles)\n",
    "    .map(partial(lacss.data.flip_left_right, p=0.5))\n",
    "    .map(partial(lacss.data.flip_up_down, p=0.5))\n",
    "    .map(parser)\n",
    "    .repeat()\n",
    "    .prefetch(1)\n",
    ")\n",
    "\n",
    "# make sure the dataset has the correct element structure\n",
    "ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GESuO6zM9tso"
   },
   "source": [
    "## Initialize a trainer\n",
    "\n",
    "The ```lacss.train.LacssTrainer``` class is the main interface we use for training. It needs a few things to start:\n",
    "\n",
    "- A configuration dictionary to override the default model hyperparameters.\n",
    "- An optional random seed value to control the process of stochastic grandient descent\n",
    "- An optional strategy specify the training backend to use. Here we used VMapped which is suitable for single GPU training on batched data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2mp9sJM-Tul",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "from xtrain import Trainer, VMapped\n",
    "from lacss.modules import Lacss\n",
    "from lacss.losses import supervised_instance_loss\n",
    "\n",
    "model = Lacss.get_small_model()\n",
    "model.detector.max_output = 256 # reduce max number of cells per image to save a bit time\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    losses = (\n",
    "      \"losses/lpn_detection_loss\", \n",
    "      \"losses/lpn_localization_loss\",\n",
    "      supervised_instance_loss,\n",
    "    ),\n",
    "    optimizer = optax.adamw(1e-4),\n",
    ")\n",
    "\n",
    "#current model hyper-parameters\n",
    "\n",
    "print(\"---Current model configuration---\")\n",
    "pprint(\n",
    "    asdict(trainer.model), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5qcbxs5aomk"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09jrmOyjaoAs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_steps = 15000\n",
    "validation_interval = 3000\n",
    "\n",
    "train_it = trainer.train(ds, rng_cols=\"dropout\", training=True)\n",
    "\n",
    "with tqdm(total=n_steps) as pbar:\n",
    "    while train_it.step < n_steps:\n",
    "        pred = next(train_it)\n",
    "        pbar.update(1)\n",
    "\n",
    "        if train_it.step % validation_interval == 0:\n",
    "            pprint(train_it.loss_logs)\n",
    "            train_it.reset_loss_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_tBseBbc-mw"
   },
   "source": [
    "## Visualize the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qOX43ZnYyX-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.color import label2rgb\n",
    "from lacss.ops import patches_to_label\n",
    "\n",
    "image = imageio.imread(data_path/'test'/'000_img.png')\n",
    "gt = imageio.imread(data_path/'test'/'000_masks.png')\n",
    "\n",
    "#noramlize image\n",
    "img = tf.image.per_image_standardization(image).numpy()\n",
    "\n",
    "# prediction\n",
    "model_output = trainer.model.apply(\n",
    "    dict(params = train_it.parameters),\n",
    "    image = img,\n",
    ")\n",
    "pred = patches_to_label(\n",
    "    model_output[\"predictions\"], \n",
    "    input_size=image.shape[:2]\n",
    ")\n",
    "pred = np.asarray(pred)\n",
    "\n",
    "show_images([\n",
    "    image,\n",
    "    label2rgb(pred, bg_label=0),\n",
    "    label2rgb(gt, bg_label=0),\n",
    "])\n",
    "titles = ['Input', \"Prediction\", \"Ground Truth\"]\n",
    "[ax.set_title(title) for ax, title in zip(plt.gcf().get_axes(), titles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's more?\n",
    "\n",
    "- You can train for more steps\n",
    "- You can perform quantitative evaluation\n",
    "- You can incorporate validation and checkpointing into the training loop\n",
    "- You can export the trained model\n",
    "\n",
    "Check the [documentation](https://jiyuuchc.github.io/lacss/api/deploy/) for details."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
