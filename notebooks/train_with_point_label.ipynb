{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kks5J-TD8-Bh"
   },
   "source": [
    "# LACSS Point-supervised Training Demo\n",
    "\n",
    "The demo will train a model to segment microscopy images of cells, using only point label.\n",
    "\n",
    " * The point label was produced automatically from DAPI images\n",
    "\n",
    "We will go through these steps:\n",
    "\n",
    "- Setup the data pipeline\n",
    "\n",
    "- Initialize a model trainer\n",
    "\n",
    "- Perform model training\n",
    "\n",
    "- Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jp1Y6zHl9ddY"
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"lacss[train] @ git+https://github.com/jiyuuchc/lacss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ivh9LzC89QK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "import lacss.data\n",
    "from lacss.utils import show_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr0QliBABDOh"
   },
   "source": [
    "## Data pipeline\n",
    "\n",
    "Lacss expect training data from a python generator that produces the following data:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"image\": ndarray[B, W, H, C],\n",
    "  \"gt_locations\": ndarray[B, N, 2]\n",
    "}\n",
    "```\n",
    "\n",
    "Here we will set up the data pipeline using tensorflow.dataset library, which has many useful utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rqdox1oOccv4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!wget -c https://data.mendeley.com/public-files/datasets/89s3ymz5wn/files/f976856c-08c5-4bba-85a7-3881e0593115/file_downloaded -O A431.zip\n",
    "\n",
    "import zipfile\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "data_path = Path('image_data')\n",
    "with zipfile.ZipFile('A431.zip', \"r\") as f:\n",
    "    f.extractall(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3bSK8QDEKlM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lacss.data import simple_generator\n",
    "from lacss.data.utils import gf_batch, gf_cycle, image_standardization\n",
    "import lacss.data.augment_ as augment\n",
    "\n",
    "BATCHSIZE = 1\n",
    "\n",
    "@gf_batch(batch_size=BATCHSIZE)\n",
    "@gf_cycle\n",
    "def dataset_generator():\n",
    "    for data in simple_generator(data_path/\"train.json\", data_path/\"train\"):\n",
    "\n",
    "        # simple augmentation\n",
    "        data = augment.flip_left_right(data, p = 0.5)\n",
    "        data = augment.flip_up_down(data, p = 0.5)\n",
    "\n",
    "        # It is important to pad the locations tensor so that all elements of the dataset are of the same shape\n",
    "        locations = data['centroids']\n",
    "        n_pad = 1024 - len(locations)\n",
    "        locations = np.pad(locations, [[0, n_pad], [0,0]], constant_values=-1)\n",
    "\n",
    "        yield dict(\n",
    "            image = image_standardization(data['image']),\n",
    "            gt_locations = locations,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show an example of the training data\n",
    "\n",
    "data = next(dataset_generator())\n",
    "img = data['image'][0]\n",
    "img = img - img.min()\n",
    "img /= img.max()\n",
    "locations = data['gt_locations'][0]\n",
    "\n",
    "show_images([\n",
    "    img,\n",
    "    np.zeros_like(img),\n",
    "])\n",
    "ax = plt.gcf().get_axes()\n",
    "ax[0].set_title(\"Image\")\n",
    "for pos in locations:\n",
    "    c = Circle((pos[1], pos[0]), radius=2, edgecolor='white')\n",
    "    ax[1].add_patch(c)\n",
    "ax[1].set_title(\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GESuO6zM9tso"
   },
   "source": [
    "## Initialize a trainer\n",
    "\n",
    "To speed up the training, we will start from a model pre-trained on LiveCell dataset (bright field microscopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2mp9sJM-Tul",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "from functools import partial\n",
    "from ml_collections import ConfigDict\n",
    "from lacss.train import Trainer, train_fn, CKS\n",
    "from lacss.modules import Lacss\n",
    "\n",
    "# Normally we don't segment all cells during training to save time\n",
    "# But for CKS, we need to ensure all cells are segmented\n",
    "config = ConfigDict()\n",
    "config.max_training_instances = 1024\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = Lacss.get_small_model(),\n",
    "    optimizer = optax.adam(1e-4),\n",
    "    losses = [], # losses is ignored by the CKS module\n",
    "    strategy = CKS, # The CKS module implements the training logic\n",
    ")\n",
    "\n",
    "method = partial(train_fn, config=config)\n",
    "it = trainer.train(dataset_generator, method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5qcbxs5aomk"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09jrmOyjaoAs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_steps = 15000\n",
    "validation_interval = 3000\n",
    "\n",
    "for step in tqdm(range(n_steps)):\n",
    "\n",
    "    if (step + 1) % validation_interval == 0:\n",
    "        print(it.variables['cks'].loss)\n",
    "        it.reset_loss_logs()\n",
    "\n",
    "    next(it)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_tBseBbc-mw"
   },
   "source": [
    "## Visualize  the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qOX43ZnYyX-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lacss.deploy.predict import Predictor\n",
    "from lacss.data.utils import image_standardization\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "# get data\n",
    "image = imageio.imread(data_path/'test'/'img_0001.tif')\n",
    "gt_label = imageio.imread(data_path/'test'/'masks_0001.tif')\n",
    "\n",
    "# predict\n",
    "predictor = Predictor((model, it.parameters))\n",
    "label = predictor.predict(image, score_threshold=0.4)[\"pred_label\"]\n",
    "\n",
    "show_images([\n",
    "    image,\n",
    "    label2rgb(np.asarray(label), bg_label=0),\n",
    "    label2rgb(gt_label, bg_label=0),\n",
    "])\n",
    "titles = ['Input', \"Prediction\", \"Ground Truth\"]\n",
    "[ax.set_title(title) for ax, title in zip(plt.gcf().get_axes(), titles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's more?\n",
    "\n",
    "- You can train for more steps\n",
    "- You can perform quantitative evaluation\n",
    "- You can incorporate validation and checkpointing into the training loop\n",
    "- You can export the trained model\n",
    "\n",
    "Check the [documentation](https://jiyuuchc.github.io/lacss/api/deploy/) for details."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
